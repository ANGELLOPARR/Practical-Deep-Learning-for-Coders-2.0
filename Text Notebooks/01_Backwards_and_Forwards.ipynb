{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "01_Backwards_and_Forwards.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8LT8Oe-LmJLT",
        "colab_type": "text"
      },
      "source": [
        "# 01 Backwards and Forwards Models"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nMLUEj8bmRN4",
        "colab_type": "text"
      },
      "source": [
        "The final bit for today is looking at ensembling backwards and forwards models. \n",
        "\n",
        "The technique can be boiled down as simply reversing the entire sentence. We train two models, one forwards and one backwards, and ensemble the two of them. Both the language model and the downstream'd model have this augmentation applied.\n",
        "\n",
        "We need to make two modifications to get this to work, a transform to reverse and a modified `learner` to enable us to get the pretrained langauge model:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_F1D_DL0mkcD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install fastai2"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PJ6ECglvmFrr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from fastai2.text.all import *"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4qEM0L_WmkC-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "path = untar_data(URLs.IMDB_SAMPLE)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ml34M9EtmnBU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df = pd.read_csv(path/'texts.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u_Gv8WPemqZh",
        "colab_type": "text"
      },
      "source": [
        "We reverse each individual text inside of the batch:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BpLQkKmFmn5N",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def reverse_text(x): return torch.stack([a.flip(0) for a in x])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UPLMUgzXmt-u",
        "colab_type": "text"
      },
      "source": [
        "Let's build two LM DataLoaders to see this in action, one with reverse and one without:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mgeLZ0OZZGVL",
        "colab_type": "text"
      },
      "source": [
        "First the regular (forwards) `DataBlock` and `DataLoaders`:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G1skMxXOmsXK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "lm_block = TextBlock.from_df('text', is_lm=True, res_col_name='tok_text')\n",
        "dblock = DataBlock(blocks=lm_block,\n",
        "                   get_x=ColReader('tok_text'),\n",
        "                   splitter=RandomSplitter(0.1, seed=42))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7ZjQMaqumyTt",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "outputId": "8c91be31-7836-4a57-ffcf-2efc06e018d0"
      },
      "source": [
        "dls = dblock.dataloaders(df, bs=64, seq_len=72, num_workers=4)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              ""
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qCB4A-VfZKEn",
        "colab_type": "text"
      },
      "source": [
        "Then our new backwards one, with an added `batch_tfm` of our `reverse_text` function:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_-53ui1vm3b4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "lm_block = TextBlock.from_df('text', is_lm=True, res_col_name='tok_text')\n",
        "dblock = DataBlock(blocks=lm_block,\n",
        "                   get_x=ColReader('tok_text'),\n",
        "                   splitter=RandomSplitter(0.1, seed=42),\n",
        "                   batch_tfms=reverse_text)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CFH1F9scpxoM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "outputId": "442f2899-3a08-4158-e9fd-711ad21dd880"
      },
      "source": [
        "dls_r = dblock.dataloaders(df, bs=64, seq_len=72, num_workers=4)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              ""
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "us9qJ8DkZOxU",
        "colab_type": "text"
      },
      "source": [
        "Let's take a look at our backwards `DataLoader` to make sure it is working:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b9DEHlwDqEmo",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "7abfd7c4-9372-42c6-956b-ac150075e084"
      },
      "source": [
        "dls_r.show_batch()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>text_</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>make go xxmaj \\n\\n ! you tell will i \\n\\n ? do to going you are what now so xxmaj ? stacking needs xxunk the and telly the on football no is there and night stormy and dark a 's it xxmaj . home at are though you xxmaj ? law in mother the visiting is wife the xxmaj ? over - sleep a on away are xxunk your so xxmaj xxbos</td>\n",
              "      <td>an make go xxmaj \\n\\n ! you tell will i \\n\\n ? do to going you are what now so xxmaj ? stacking needs xxunk the and telly the on football no is there and night stormy and dark a 's it xxmaj . home at are though you xxmaj ? law in mother the visiting is wife the xxmaj ? over - sleep a on away are xxunk your so xxmaj</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>and , fish some and , xxunk and xxunk only but , animal of kind each of something see we xxmaj . is it xxunk or pole north from far how indication an with starts \" chapter \" each xxmaj . parts these of one than more in appear , xxunk and elephant , bear polar , families animal 3 . xxunk xxmaj to pole xxmaj north xxmaj from earth on life</td>\n",
              "      <td>some and , fish some and , xxunk and xxunk only but , animal of kind each of something see we xxmaj . is it xxunk or pole north from far how indication an with starts \" chapter \" each xxmaj . parts these of one than more in appear , xxunk and elephant , bear polar , families animal 3 . xxunk xxmaj to pole xxmaj north xxmaj from earth on</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>boys of team a on own her hold to try frankie xxmaj watch to painful quite was it , myself player baseball a being xxmaj . baseball and ballet : xxunk two her and , grandmother her , friend best her between balance a keep to hard work to has she how see to interesting 's it xxmaj . off … bit a is frankie xxmaj and hazel xxmaj between relationship the</td>\n",
              "      <td>, boys of team a on own her hold to try frankie xxmaj watch to painful quite was it , myself player baseball a being xxmaj . baseball and ballet : xxunk two her and , grandmother her , friend best her between balance a keep to hard work to has she how see to interesting 's it xxmaj . off … bit a is frankie xxmaj and hazel xxmaj between relationship</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>the to death out deals xxunk he as xxunk appropriately is \" xxunk xxmaj the \" of delon xxmaj xxunk xxmaj . killings sudden often and savage of lots with entertainment solid as qualifies still it but , predictable rather is \" guns xxmaj big \" , indeed xxmaj . wire the to down right mob the for gunman career a about xxunk this take \" death xxmaj of ring \" of</td>\n",
              "      <td>heads the to death out deals xxunk he as xxunk appropriately is \" xxunk xxmaj the \" of delon xxmaj xxunk xxmaj . killings sudden often and savage of lots with entertainment solid as qualifies still it but , predictable rather is \" guns xxmaj big \" , indeed xxmaj . wire the to down right mob the for gunman career a about xxunk this take \" death xxmaj of ring \"</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>oates xxmaj warren xxmaj great the wasting completely 's it , crime real 's film the know to want you if but xxmaj . economically more much all it says , xxunk xxmaj the across xxmaj , song title beautiful 's xxunk xxmaj xxunk xxmaj unfortunately xxmaj . jarring more the all is melodrama into xxunk sudden the that xxunk and flat so is film the of rest the that is clumsy</td>\n",
              "      <td>in oates xxmaj warren xxmaj great the wasting completely 's it , crime real 's film the know to want you if but xxmaj . economically more much all it says , xxunk xxmaj the across xxmaj , song title beautiful 's xxunk xxmaj xxunk xxmaj unfortunately xxmaj . jarring more the all is melodrama into xxunk sudden the that xxunk and flat so is film the of rest the that is</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>xxmaj tom xxmaj with big xxmaj loved i \\n\\n . good is which … happen n't did that , wow but … appear to mother god fairy the for waiting was xxmaj … corny so xxup * xxunk * … part past the to back going the … but , okay was it thought i end the till up xxmaj … once than more done been has it … but , movie</td>\n",
              "      <td>hanks xxmaj tom xxmaj with big xxmaj loved i \\n\\n . good is which … happen n't did that , wow but … appear to mother god fairy the for waiting was xxmaj … corny so xxup * xxunk * … part past the to back going the … but , okay was it thought i end the till up xxmaj … once than more done been has it … but ,</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>on standing never and him around forces by manipulated , xxunk constantly , xxunk a as portrayed is he scenes first the from : recognizable barely is frodo xxmaj 's tolkien xxmaj version jackson xxmaj the in xxmaj \\n\\n . concerned are characters the as far so especially , source the to xxunk stays it flaws its has film this while xxmaj . version xxunk the than tolkien xxmaj to homage xxunk</td>\n",
              "      <td>his on standing never and him around forces by manipulated , xxunk constantly , xxunk a as portrayed is he scenes first the from : recognizable barely is frodo xxmaj 's tolkien xxmaj version jackson xxmaj the in xxmaj \\n\\n . concerned are characters the as far so especially , source the to xxunk stays it flaws its has film this while xxmaj . version xxunk the than tolkien xxmaj to homage</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>xxbos . shot be to needs one that made whoever xxmaj . xxunk me made it xxunk many so smoked kid that xxmaj . movie \" dahmer \" lame that is worse xxup consider would i movie killer serial only the xxmaj . pitiful absolutely xxmaj . achieved has it fame the of because \" btk \" term the on based movie their watching into people lure to trying someone of example</td>\n",
              "      <td>xxmaj xxbos . shot be to needs one that made whoever xxmaj . xxunk me made it xxunk many so smoked kid that xxmaj . movie \" dahmer \" lame that is worse xxup consider would i movie killer serial only the xxmaj . pitiful absolutely xxmaj . achieved has it fame the of because \" btk \" term the on based movie their watching into people lure to trying someone of</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>an for nominated be na gon n't are they xxmaj . really xxmaj . competent : dialogue and acting the xxmaj \\n\\n▁ ! ending an 's that xxup now , battle climatic the out check just xxmaj . noises loud of plenty have and , xxunk terrific have , handled well are they xxmaj . superb : scenes action the for as xxmaj \\n\\n▁ . succeeds it and xxmaj . ice xxmaj</td>\n",
              "      <td>xxmaj an for nominated be na gon n't are they xxmaj . really xxmaj . competent : dialogue and acting the xxmaj \\n\\n▁ ! ending an 's that xxup now , battle climatic the out check just xxmaj . noises loud of plenty have and , xxunk terrific have , handled well are they xxmaj . superb : scenes action the for as xxmaj \\n\\n▁ . succeeds it and xxmaj . ice</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gCUtQrC1m9ui",
        "colab_type": "text"
      },
      "source": [
        "So how do we know? Let's look at the first batch in our validation sets:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g1rdyyrBm9Wf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "b_f = next(iter(dls[1]))\n",
        "b_b = next(iter(dls_r[1]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nfh9p2LFnCKt",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 134
        },
        "outputId": "72212994-b8ec-4855-825b-a35e84840b7d"
      },
      "source": [
        "b_f[0]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LMTensorText([[   2,    8,   28,  ...,    0,   12,  211],\n",
              "        [ 637,   31,   33,  ...,   41,  286,   18],\n",
              "        [  15,  345, 3432,  ...,  114, 2502,   12],\n",
              "        ...,\n",
              "        [ 246,    0,   11,  ...,   19,   85,   44],\n",
              "        [ 500,   37,   43,  ..., 3801,  798,   66],\n",
              "        [3014,   10,    8,  ...,   24,  124,   54]], device='cuda:0')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 60
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "80RY617hnEK7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 134
        },
        "outputId": "0efbc909-1468-4465-9fb6-f574b484644d"
      },
      "source": [
        "b_b[0]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LMTensorText([[ 211,   12,    0,  ...,   28,    8,    2],\n",
              "        [  18,  286,   41,  ...,   33,   31,  637],\n",
              "        [  12, 2502,  114,  ..., 3432,  345,   15],\n",
              "        ...,\n",
              "        [  44,   85,   19,  ...,   11,    0,  246],\n",
              "        [  66,  798, 3801,  ...,   43,   37,  500],\n",
              "        [  54,  124,   24,  ...,    8,   10, 3014]], device='cuda:0')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 61
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WItDJCNBnG4v",
        "colab_type": "text"
      },
      "source": [
        "We can see that each word is simply 100% reversed. There are some other augmentation techniques too, such as translation that we may look at later"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tZBkXbgPnobv",
        "colab_type": "text"
      },
      "source": [
        "The last thing we need is a way to enable us to grab the backwards language model inside of `language_model_learner`:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l_q_lpTlnoGO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def _get_text_vocab(dls):\n",
        "    vocab = dls.vocab\n",
        "    if isinstance(vocab, L): vocab = vocab[0]\n",
        "    return vocab\n",
        "\n",
        "from fastai2.text.models.core import _model_meta\n",
        "\n",
        "def language_model_learner(dls, arch, config=None, drop_mult=1., backwards=True, pretrained=True, pretrained_fnames=None, **kwargs):\n",
        "    \"Create a `Learner` with a language model from `dls` and `arch`.\"\n",
        "    vocab = _get_text_vocab(dls)\n",
        "    model = get_language_model(arch, len(vocab), config=config, drop_mult=drop_mult)\n",
        "    meta = _model_meta[arch]\n",
        "    learn = LMLearner(dls, model, loss_func=CrossEntropyLossFlat(), splitter=meta['split_lm'], **kwargs)\n",
        "    #TODO: add backard\n",
        "    url = 'url_bwd' if backwards else 'url'\n",
        "    if pretrained or pretrained_fnames:\n",
        "        if pretrained_fnames is not None:\n",
        "            fnames = [learn.path/learn.model_dir/f'{fn}.{ext}' for fn,ext in zip(pretrained_fnames, ['pth', 'pkl'])]\n",
        "        else:\n",
        "            if url not in meta:\n",
        "                warn(\"There are no pretrained weights for that architecture yet!\")\n",
        "                return learn\n",
        "            model_path = untar_data(meta[url] , c_key='model')\n",
        "            fnames = [list(model_path.glob(f'*.{ext}'))[0] for ext in ['pth', 'pkl']]\n",
        "        learn = learn.load_pretrained(*fnames)\n",
        "    return learn"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xj56BTNBZUJQ",
        "colab_type": "text"
      },
      "source": [
        "Now this is still in the in-progress stage at this moment, it'll be more in-house once it's finished and I'll update this notebook accordingly"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4TP6q-NVnUTM",
        "colab_type": "text"
      },
      "source": [
        "## Training\n",
        "\n",
        "So for training, this will be an ensemble of two models, a forwards and a backwards model. We'll train all the models all at once and save them away into an array:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3vANnX13nGLF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train_models(models:list):\n",
        "    names = ['fwd', 'bwd']\n",
        "    for i, model in enumerate(models):\n",
        "        lr = 1e-2\n",
        "        lr *= model.dls.bs/48\n",
        "        model = model.to_fp16()\n",
        "        model.fine_tune(5)\n",
        "        model.save_encoder(f'{names[i]}_fine_tuned_enc')\n",
        "    return models"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bLHXpa1boFcO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "fwd = language_model_learner(dls, AWD_LSTM, backwards=False, metrics=[accuracy, Perplexity()])\n",
        "bwd = language_model_learner(dls_r, AWD_LSTM, backwards=True, metrics=[accuracy, Perplexity()])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QnsGuVJFoQMT",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 494
        },
        "outputId": "b70fdc7b-9060-49f6-9de3-5e844973ab90"
      },
      "source": [
        "spp = train_models([fwd, bwd])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: left;\">\n",
              "      <th>epoch</th>\n",
              "      <th>train_loss</th>\n",
              "      <th>valid_loss</th>\n",
              "      <th>accuracy</th>\n",
              "      <th>perplexity</th>\n",
              "      <th>time</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>0</td>\n",
              "      <td>4.860167</td>\n",
              "      <td>4.186048</td>\n",
              "      <td>0.269258</td>\n",
              "      <td>65.762352</td>\n",
              "      <td>00:07</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: left;\">\n",
              "      <th>epoch</th>\n",
              "      <th>train_loss</th>\n",
              "      <th>valid_loss</th>\n",
              "      <th>accuracy</th>\n",
              "      <th>perplexity</th>\n",
              "      <th>time</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>0</td>\n",
              "      <td>4.682951</td>\n",
              "      <td>4.120397</td>\n",
              "      <td>0.273857</td>\n",
              "      <td>61.583664</td>\n",
              "      <td>00:09</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>4.579101</td>\n",
              "      <td>4.061773</td>\n",
              "      <td>0.277470</td>\n",
              "      <td>58.077179</td>\n",
              "      <td>00:09</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>4.482619</td>\n",
              "      <td>4.028481</td>\n",
              "      <td>0.280158</td>\n",
              "      <td>56.175491</td>\n",
              "      <td>00:09</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>4.421196</td>\n",
              "      <td>4.012850</td>\n",
              "      <td>0.279926</td>\n",
              "      <td>55.304253</td>\n",
              "      <td>00:09</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>4.387582</td>\n",
              "      <td>4.009764</td>\n",
              "      <td>0.279356</td>\n",
              "      <td>55.133842</td>\n",
              "      <td>00:09</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: left;\">\n",
              "      <th>epoch</th>\n",
              "      <th>train_loss</th>\n",
              "      <th>valid_loss</th>\n",
              "      <th>accuracy</th>\n",
              "      <th>perplexity</th>\n",
              "      <th>time</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>0</td>\n",
              "      <td>7.599288</td>\n",
              "      <td>6.916414</td>\n",
              "      <td>0.058263</td>\n",
              "      <td>1008.696106</td>\n",
              "      <td>00:08</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: left;\">\n",
              "      <th>epoch</th>\n",
              "      <th>train_loss</th>\n",
              "      <th>valid_loss</th>\n",
              "      <th>accuracy</th>\n",
              "      <th>perplexity</th>\n",
              "      <th>time</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>0</td>\n",
              "      <td>6.295796</td>\n",
              "      <td>5.560562</td>\n",
              "      <td>0.113570</td>\n",
              "      <td>259.968933</td>\n",
              "      <td>00:09</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>5.157556</td>\n",
              "      <td>4.005322</td>\n",
              "      <td>0.291526</td>\n",
              "      <td>54.889469</td>\n",
              "      <td>00:09</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>4.162626</td>\n",
              "      <td>3.041760</td>\n",
              "      <td>0.433004</td>\n",
              "      <td>20.942068</td>\n",
              "      <td>00:09</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>3.536577</td>\n",
              "      <td>2.673681</td>\n",
              "      <td>0.494720</td>\n",
              "      <td>14.493217</td>\n",
              "      <td>00:09</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>3.250588</td>\n",
              "      <td>2.616126</td>\n",
              "      <td>0.504535</td>\n",
              "      <td>13.682611</td>\n",
              "      <td>00:09</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "51OZD2Hqq6X9",
        "colab_type": "text"
      },
      "source": [
        "Now we just repeat what we did last time!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2F-hU_QooWZL",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "outputId": "0fc6036c-069a-4175-af64-35d3e00cf79e"
      },
      "source": [
        "blocks = (TextBlock.from_df('text', res_col_name='tok_text', seq_len=fwd.dls.seq_len,\n",
        "                            vocab=fwd.dls.vocab), CategoryBlock())\n",
        "\n",
        "imdb_class = DataBlock(blocks=blocks,\n",
        "                       get_x=ColReader('tok_text'),\n",
        "                       get_y=ColReader('label'),\n",
        "                       splitter=ColSplitter(col='is_valid'))\n",
        "fwd_dls = imdb_class.dataloaders(df, bs=32)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              ""
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JpDx87QOrVqR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def reverse_text(x:TensorText): return torch.stack([a.flip(0) for a in x])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XwAJ4dRMrKp9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "outputId": "93dd4343-03ac-46ec-bb1b-46a074e7cfc6"
      },
      "source": [
        "blocks = (TextBlock.from_df('text', res_col_name='tok_text', seq_len=bwd.dls.seq_len,\n",
        "                            vocab=bwd.dls.vocab), CategoryBlock())\n",
        "\n",
        "imdb_class = DataBlock(blocks=blocks,\n",
        "                       get_x=ColReader('tok_text'),\n",
        "                       get_y=ColReader('label'),\n",
        "                       splitter=ColSplitter(col='is_valid'),\n",
        "                       batch_tfms=reverse_text)\n",
        "bwd_dls = imdb_class.dataloaders(df, bs=32)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              ""
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r6tG8BrprQEJ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "aca9c47d-6438-4306-d79a-e4ef6829aa30"
      },
      "source": [
        "bwd_dls.show_batch()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>category</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>. xxunk of bowl a into hands my stick go to going 'm i xxmaj , me excuse 'll you if so xxmaj ? him about film a like i can how ultimately so , him like n't do i way either xxmaj ' ? xxunk - xxunk xxunk my into get to want xxunk , xxunk - bay hey ` , car his from girls to shouting up end just 'll who , latino xxmaj blooded - hot stereotypical a merely is vargas xxmaj victor xxmaj , film the by xxunk further any without because 's it maybe xxmaj . xxunk was i when xxunk xxmaj xxunk xxmaj my with playing was i while laid getting were who guys those of me reminds vargas xxmaj victor xxmaj because 's it maybe xxmaj . film the for feelings my xxunk vargas xxmaj victor xxmaj for respect of lack my ,</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>. could possibly very we that feeling it from away come we that is film this about thing best the ; film this in depicted romance the have to as lucky so be all should we xxmaj . role his in xxunk is stewart xxmaj and , charming , funny , sweet 's it xxmaj . instead christmas xxmaj this corner xxup the xxup around xxup shop xxup the xxup watching in done , good of lot a fact in and , harm no be 'd there but , film other that of merits the from xxunk to not xxmaj . life xxup wonderful xxup a 's it xxup about talk they when on out missing are people that film christmas xxmaj stewart xxmaj jimmy xxmaj the really is * this * \\n\\n ) . mail xxup got xxup 've you xxup like remake a in even not , no</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>) 10 / xxunk the about xxunk a just even know who all of hearts the break to bound is it xxmaj . costs all at avoided be to , film soderbergh xxmaj a for , xxunk -- misery irritating , confusing just is xxunk cinema xxunk this of rest the xxmaj \\n\\n . subject 's film the of execution and capture -- tragic yet -- dramatic the and , humour aforementioned the by redeemed only is half second entire the xxmaj . xxunk and misery of picture a it painting , xxunk xxmaj for xxunk no certainly is part2 xxmaj aka xxunk xxmaj the : che \\n\\n . \" turgid and slow unbearably almost feels … \" which , \" detail excruciating in xxunk xxmaj in campaign final 's che xxmaj xxunk \" , there from \" downhill rapidly goes \" actually part2 xxmaj , \" uneven \" was</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>. end xxup the xxup . other each at look they xxmaj . window the down xxunk , up drives movie the in earlier her pay n't did who contractor the xxmaj . business does normally she where corner the at xxunk and , street the down walking prostitute the see we and , off goes gun the , eventually xxmaj . aim to where her telling , mouth his inside gun the holding , hand her holding , insists he but , it do to want not does prostitute the xxmaj . it do n't could but , himself kill to tried he xxmaj . him kill will she if cash in 0 3 xxrep , xxunk $ him give to wants she xxmaj . xxunk xxmaj la xxmaj out started who prostitute same the to , beginning the to back come we and , xxunk brooklyn xxmaj the</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>. there xxunk interesting have they least at , xxunk an for office 's doctor a at waiting fun more have 'll you xxmaj . else something do go = boring xxmaj + boring xxmaj + boring xxmaj : points three my summarize to xxmaj . xxunk mind is handled was show this which in manner incompetent xxunk the but , nature this of show a up putting first for bravo xxmaj commend do i . xxunk be to needed that issues were these felt i but winded long was this if sorry xxmaj \\n\\n . compromise to refuses show this xxmaj . kisses xxunk and xxunk xxunk than more want na gon are shows tv xxup reality watch who people xxmaj . on * 4 xxrep the come but , men homosexual of nature xxunk xxunk the up play to wanting not them understand can i . ridiculous 's</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>10 / 8 . games 3d of fans all to this recommended i . appeared first he after years fifteen nearly ) ? especially even maybe xxunk , recognition the deserves he … shoes 's . xxunk into step and bunker the enter to door the open , xxunk xxmaj the up load so xxmaj . one this to existence their owe , genre the of rest the as well as , games those of all but … ) here out me help , xxunk fellow xxmaj ? possibly , xxunk xxmaj first xxunk later , third a until around come n't did jumping and , ) it to xxunk xxunk adding , right and left simply beyond goes it xxunk your switching of feature the introduced that 3d xxunk xxmaj duke xxmaj was it and … doom xxmaj … genre the into entry next the until around come n't</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>. out make to seem many classic the not definitely xxmaj . own 's it on one song theme main wonderful that give &amp; stars two film the give 'll i xxmaj . respect every in film better a 's it as time every remake the , one easy an is choice the xxmaj . town entire an eats virtually it &amp; through way the all blob the features remake the &amp; film entire the throughout people four or three only eating time screen little very gets itself blob xxmaj original the &amp; n't does remake the &amp; decisions casting &amp; acting poor incredibly has blob xxmaj original the , does remake the &amp; gore or blood no contains blob xxmaj original the , n't is remake the &amp; boring &amp; slow is blob xxmaj original the xxmaj . original the than better definitely is ) xxunk ( blob xxmaj</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>! film this see  it of version distorted wholly some not and  worlds xxmaj the of war xxmaj ' wells xxmaj g. xxup h. xxup see to want you if xxmaj . xxunk up - xxunk its of any than better away and far is it , xxunk slight its despite xxmaj . it wrote wells xxmaj as worlds xxmaj the of war xxmaj the time first the for portraying , film splendid a overall is this xxmaj \\n\\n . film first his in xxunk xxmaj james xxmaj by played is , part xxunk other only the , xxunk xxmaj the xxmaj . film first his in xxunk xxmaj xxunk xxmaj xxunk xxup by conviction some with played is ) \" henderson \" ( brother xxmaj the xxmaj . directing experience more had has who but actor an as film 2nd his in also  xxunk xxmaj john</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>. photographer ugly and fat the , character main - \" ! you have i ! ugly 're you xxmaj ! fat 're you xxmaj ! you hate i ! you hate i \" ] mirror the in herself at looking while [ \\n\\n . xxunk of school own her of head , xxunk proclaimed self some xxmaj - \" xxunk an has he yet an xxmaj . within are changes the all , outside the on changes nothing xxmaj . thought one just takes it xxmaj ? xxunk an have to man one for take it does what \" \\n\\n . physics quantum of xxunk the on head talking some xxmaj - \" . unreal the than real less lot a xxunk is , real consider to used i which , that and , me to real more lot a become has unreal as of think i what \"</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_-X7SHXwrKJB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "fwd = text_classifier_learner(fwd_dls, AWD_LSTM, backwards=False, metrics=[accuracy])\n",
        "bwd = text_classifier_learner(bwd_dls, AWD_LSTM, backwards=True, metrics=[accuracy])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N8l5_9zurmWJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "fwd.load_encoder('fwd_fine_tuned_enc');\n",
        "bwd.load_encoder('bwd_fine_tuned_enc');"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PPChb0zvrxmi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train_class(models:list):\n",
        "    for i, model in enumerate(models):\n",
        "        lr = 0.04365158379077912\n",
        "        adj = 2.6**4\n",
        "        model.fit_one_cycle(1, lr)\n",
        "        model.freeze_to(-2)\n",
        "        model.fit_one_cycle(1, slice(lr/adj, lr))\n",
        "        model.freeze_to(-3)\n",
        "        lr /= 2\n",
        "        model.fit_one_cycle(1, slice(lr/adj, lr))\n",
        "        model.unfreeze()\n",
        "        lr /= 5\n",
        "        model.fit_one_cycle(2, slice(lr/adj, lr))\n",
        "    return models"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dHBNtR5AsFyP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "models = [fwd,bwd]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vbfvuCUAsHev",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 556
        },
        "outputId": "f798b0ce-e797-487a-ddf0-2c36b0673683"
      },
      "source": [
        "models = train_class(models)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: left;\">\n",
              "      <th>epoch</th>\n",
              "      <th>train_loss</th>\n",
              "      <th>valid_loss</th>\n",
              "      <th>accuracy</th>\n",
              "      <th>time</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>0</td>\n",
              "      <td>0.655381</td>\n",
              "      <td>0.621292</td>\n",
              "      <td>0.620000</td>\n",
              "      <td>00:04</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: left;\">\n",
              "      <th>epoch</th>\n",
              "      <th>train_loss</th>\n",
              "      <th>valid_loss</th>\n",
              "      <th>accuracy</th>\n",
              "      <th>time</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>0</td>\n",
              "      <td>0.628992</td>\n",
              "      <td>0.533796</td>\n",
              "      <td>0.735000</td>\n",
              "      <td>00:05</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: left;\">\n",
              "      <th>epoch</th>\n",
              "      <th>train_loss</th>\n",
              "      <th>valid_loss</th>\n",
              "      <th>accuracy</th>\n",
              "      <th>time</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>0</td>\n",
              "      <td>0.416536</td>\n",
              "      <td>0.434743</td>\n",
              "      <td>0.800000</td>\n",
              "      <td>00:07</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: left;\">\n",
              "      <th>epoch</th>\n",
              "      <th>train_loss</th>\n",
              "      <th>valid_loss</th>\n",
              "      <th>accuracy</th>\n",
              "      <th>time</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>0</td>\n",
              "      <td>0.365156</td>\n",
              "      <td>0.416463</td>\n",
              "      <td>0.805000</td>\n",
              "      <td>00:09</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.282378</td>\n",
              "      <td>0.416023</td>\n",
              "      <td>0.810000</td>\n",
              "      <td>00:09</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: left;\">\n",
              "      <th>epoch</th>\n",
              "      <th>train_loss</th>\n",
              "      <th>valid_loss</th>\n",
              "      <th>accuracy</th>\n",
              "      <th>time</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>0</td>\n",
              "      <td>0.759698</td>\n",
              "      <td>0.584659</td>\n",
              "      <td>0.705000</td>\n",
              "      <td>00:04</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: left;\">\n",
              "      <th>epoch</th>\n",
              "      <th>train_loss</th>\n",
              "      <th>valid_loss</th>\n",
              "      <th>accuracy</th>\n",
              "      <th>time</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>0</td>\n",
              "      <td>0.695663</td>\n",
              "      <td>0.549426</td>\n",
              "      <td>0.735000</td>\n",
              "      <td>00:04</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: left;\">\n",
              "      <th>epoch</th>\n",
              "      <th>train_loss</th>\n",
              "      <th>valid_loss</th>\n",
              "      <th>accuracy</th>\n",
              "      <th>time</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>0</td>\n",
              "      <td>0.541979</td>\n",
              "      <td>0.501881</td>\n",
              "      <td>0.780000</td>\n",
              "      <td>00:07</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: left;\">\n",
              "      <th>epoch</th>\n",
              "      <th>train_loss</th>\n",
              "      <th>valid_loss</th>\n",
              "      <th>accuracy</th>\n",
              "      <th>time</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>0</td>\n",
              "      <td>0.417659</td>\n",
              "      <td>0.531670</td>\n",
              "      <td>0.785000</td>\n",
              "      <td>00:09</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.333225</td>\n",
              "      <td>0.554037</td>\n",
              "      <td>0.795000</td>\n",
              "      <td>00:09</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8x_32WWhtbhG",
        "colab_type": "text"
      },
      "source": [
        "Now that we have our model, let's ensemble!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6u_ZXfOGsIfp",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "outputId": "24c2d105-d944-4805-f2cd-52e0ee0d86b5"
      },
      "source": [
        "fwd_p, y = models[0].get_preds()\n",
        "bwd_p, _ = models[1].get_preds()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              ""
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              ""
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JJYwHm07tnFV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "p = (fwd_p + bwd_p) / 2"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cErXRk8attZE",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "c8464212-f4f5-4988-cac6-75e4632cf982"
      },
      "source": [
        "accuracy(p, y)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(0.8300)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SW2FGkMIt0FU",
        "colab_type": "text"
      },
      "source": [
        "Let's compare that to both our others:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K3CxDdvltt91",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "ab9f6478-c02f-4218-b3d4-09427c2f8581"
      },
      "source": [
        "accuracy(fwd_p, y)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(0.8100)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z4bxB-OYt3Bp",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "b6a1ba74-1cfa-47aa-f156-15d65cae302f"
      },
      "source": [
        "accuracy(bwd_p, y)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(0.7950)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MjCkyhNRYHhJ",
        "colab_type": "text"
      },
      "source": [
        "|     Model Type    | Accuracy |\n",
        "|:-----------------:|:--------:|\n",
        "| Forwards (Normal) |  81.00%  |\n",
        "|     Backwards     |  79.50%  |\n",
        "|      Ensemble     |  83.00%  |\n",
        "|<img width=200/>|<img width=200/>|"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5D8aS1j7t41w",
        "colab_type": "text"
      },
      "source": [
        "We can see that even though they were well below 83%, combined they boosted up quite high!"
      ]
    }
  ]
}